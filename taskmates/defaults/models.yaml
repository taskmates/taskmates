default:
  client_type: langchain_anthropic.ChatAnthropic
  max_context_window: 4096
  model: claude-opus-4-20250514

gpt-4.1:
  client_type: langchain_openai.ChatOpenAI
  max_context_window: 1000000
  model: gpt-4.1

gpt-4o:
  client_type: langchain_openai.ChatOpenAI
  endpoint: https://api.openai.com/v1
  max_context_window: 128000
  model: gpt-4o

gpt-4o-mini:
  client_type: langchain_openai.ChatOpenAI
  endpoint: https://api.openai.com/v1
  max_context_window: 128000
  model: gpt-4o-mini

gpt-3.5-turbo:
  client_type: langchain_openai.ChatOpenAI
  endpoint: https://api.openai.com/v1
  max_context_window: 4096
  model: gpt-3.5-turbo

claude-3-haiku-20240307:
  client_type: langchain_anthropic.ChatAnthropic
  max_context_window: 4096
  model: claude-3-haiku-20240307

claude-opus-4-20250514:
  client_type: langchain_anthropic.ChatAnthropic
  max_context_window: 4096
  model: claude-opus-4-20250514

claude-sonnet-4-20250514:
  client_type: langchain_anthropic.ChatAnthropic
  max_context_window: 4096
  model: claude-sonnet-4-20250514

grok-3:
  client_type: langchain_xai.ChatXAI
  max_context_window: 131072
  model: grok-3-beta
  api_key: env:XAI_API_KEY


gemini-2.5‑pro‑preview‑06‑05:
  client_type: langchain_google_genai.ChatGoogleGenerativeAI
  max_context_window: 128000
  model: gemini-2.5‑pro‑preview‑06‑05

gemini‑2.5‑flash‑preview‑05‑20:
  client_type: langchain_google_genai.ChatGoogleGenerativeAI
  max_context_window: 128000
  model: gemini‑2.5‑flash‑preview‑05‑20

mixtral-8x7b-32768:
  client_type: langchain_openai.ChatOpenAI
  endpoint: https://api.groq.com/openai/v1
  max_context_window: 32768
  model: mixtral-8x7b-32768
  api_key: env:GROQ_API_KEY


echo:
  client_type: taskmates.core.workflows.markdown_completion.completions.llm_completion.testing.echo.Echo
  max_context_window: 64000
  model: echo

quote:
  client_type: taskmates.core.workflows.markdown_completion.completions.llm_completion.testing.quote.Quote
  max_context_window: 64000
  model: quote

fixture:
  client_type: taskmates.core.workflows.markdown_completion.completions.llm_completion.testing.fixture_chat_model.FixtureChatModel
  max_context_window: 4096


default-anthropic:
  client_type: langchain_anthropic.ChatAnthropic
  max_context_window: 4096
  model: claude-opus-4-20250514
#  client_type: taskmates.core.workflows.markdown_completion.completions.llm_completion.testing.quote.Quote
#  max_context_window: 64000
#  model: quote


codeqwen:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 64000
  model: qwen2.5-coder:32b

codellama:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: codellama:70b

deepseek-r1:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: deepseek-r1:70b

llama3.3:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: llama3.3:latest

llama4:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: llama4:latest

llava:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: llava:34b

llava-phi3:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: llava-phi3:latest

minicpm-v:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: minicpm-v:latest

moondream:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: moondream:latest

phi3:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: phi3:mini

phi4:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: phi4:latest

qwen2.5:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: qwen2.5:72b

qwen2.5-coder:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: qwen2.5-coder:32b

qwen3:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: qwen3:32b

qwq:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: qwq:latest
