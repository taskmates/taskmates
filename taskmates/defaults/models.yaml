default:
  client_type: langchain_anthropic.ChatAnthropic
  max_context_window: 4096
  model: claude-opus-4-20250514

gpt-4.1:
  client_type: langchain_openai.ChatOpenAI
  max_context_window: 1000000
  model: gpt-4.1

gpt-4o:
  client_type: langchain_openai.ChatOpenAI
  endpoint: https://api.openai.com/v1
  max_context_window: 128000
  model: gpt-4o

gpt-4o-mini:
  client_type: langchain_openai.ChatOpenAI
  endpoint: https://api.openai.com/v1
  max_context_window: 128000
  model: gpt-4o-mini

gpt-3.5-turbo:
  client_type: langchain_openai.ChatOpenAI
  endpoint: https://api.openai.com/v1
  max_context_window: 4096
  model: gpt-3.5-turbo

claude-3-haiku-20240307:
  client_type: langchain_anthropic.ChatAnthropic
  max_context_window: 4096
  model: claude-3-haiku-20240307

claude-opus-4-20250514:
  client_type: langchain_anthropic.ChatAnthropic
  max_context_window: 4096
  model: claude-opus-4-20250514

claude-sonnet-4-20250514:
  client_type: langchain_anthropic.ChatAnthropic
  max_context_window: 4096
  model: claude-sonnet-4-20250514

grok-3:
  client_type: langchain_xai.ChatXAI
  endpoint: https://api.x.ai/v1
  max_context_window: 131072
  model: grok-3-beta
  api_key: env:XAI_API_KEY


gemini-2.5‑pro‑preview‑06‑05:
  client_type: langchain_google_genai.ChatGoogleGenerativeAI
  max_context_window: 128000
  model: gemini-2.5‑pro‑preview‑06‑05

mixtral-8x7b-32768:
  client_type: langchain_openai.ChatOpenAI
  endpoint: https://api.groq.com/openai/v1
  max_context_window: 32768
  model: mixtral-8x7b-32768
  api_key: env:GROQ_API_KEY


echo:
  client_type: taskmates.core.workflows.markdown_completion.completions.llm_completion.testing.echo.Echo
  max_context_window: 64000
  model: echo

quote:
  client_type: taskmates.core.workflows.markdown_completion.completions.llm_completion.testing.quote.Quote
  max_context_window: 64000
  model: quote

fixture:
  client_type: taskmates.core.workflows.markdown_completion.completions.llm_completion.testing.fixture_chat_model.FixtureChatModel
  max_context_window: 4096


default-anthropic:
  client_type: langchain_anthropic.ChatAnthropic
  max_context_window: 4096
  model: claude-opus-4-20250514
#  client_type: taskmates.core.workflows.markdown_completion.completions.llm_completion.testing.quote.Quote
#  max_context_window: 64000
#  model: quote


codeqwen:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 64000
  model: qwen2.5-coder:32b

codellama:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: codellama

deepseek-r1:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: deepseek-r1

llama3.3:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: llama3.3

llama4:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: llama4

llava:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: llava

llava-phi3:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: llava-phi3

minicpm-v:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: minicpm-v

moondream:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: moondream

phi3:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: phi3

phi4:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: phi4

qwen2.5:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: qwen2.5

qwen2.5-coder:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: qwen2.5-coder

qwen3:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: qwen3

qwq:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 128000
  model: qwq
