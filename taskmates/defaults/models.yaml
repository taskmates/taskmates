default:
  client_type: langchain_anthropic.ChatAnthropic
  max_context_window: 4096
  model: claude-opus-4-20250514

gpt-4.1:
  client_type: langchain_openai.ChatOpenAI
  max_context_window: 1000000
  model: gpt-4.1

gpt-4o-mini:
  client_type: langchain_openai.ChatOpenAI
  endpoint: https://api.openai.com/v1
  max_context_window: 128000
  model: gpt-4o-mini

gpt-3.5-turbo:
  client_type: langchain_openai.ChatOpenAI
  endpoint: https://api.openai.com/v1
  max_context_window: 4096
  model: gpt-3.5-turbo

claude-3-haiku-20240307:
  client_type: langchain_anthropic.ChatAnthropic
  max_context_window: 4096
  model: claude-3-haiku-20240307

claude-opus-4-20250514:
  client_type: langchain_anthropic.ChatAnthropic
  max_context_window: 4096
  model: claude-opus-4-20250514

claude-sonnet-4-20250514:
  client_type: langchain_anthropic.ChatAnthropic
  max_context_window: 4096
  model: claude-sonnet-4-20250514

grok-3:
  client_type: langchain_xai.ChatXAI
  endpoint: https://api.x.ai/v1
  max_context_window: 131072
  model: grok-3-beta
  api_key: env:XAI_API_KEY


gemini-2.5-pro-exp-03-25:
  client_type: langchain_google_genai.ChatGoogleGenerativeAI
  max_context_window: 128000
  model_name: gemini-2.5-pro-exp-03-25

mixtral-8x7b-32768:
  client_type: langchain_openai.ChatOpenAI
  endpoint: https://api.groq.com/openai/v1
  max_context_window: 32768
  model: mixtral-8x7b-32768
  api_key: env:GROQ_API_KEY


llama3-70b-8192:
  client_type: langchain_google_genai.ChatGoogleGenerativeAI
  max_context_window: 128000
  model_name: llama3-70b-8192

codeqwen:
  client_type: langchain_openai.ChatOpenAI
  endpoint: http://localhost:11434/v1
  max_context_window: 64000
  model: qwen2.5-coder:32b

echo:
  client_type: taskmates.core.workflows.markdown_completion.completions.llm_completion.testing.echo.Echo
  max_context_window: 64000
  model: echo

quote:
  client_type: taskmates.core.workflows.markdown_completion.completions.llm_completion.testing.quote.Quote
  max_context_window: 64000
  model: quote

fixture:
  client_type: taskmates.core.workflows.markdown_completion.completions.llm_completion.testing.fixture_chat_model.FixtureChatModel
  max_context_window: 4096

